# 알고리즘
1. 정의
    - 유한한 단계를 통해 문제를 해결하기 위한 절차나 방법
    - 주로 컴퓨터 용어로 쓰이며, 컴퓨터가 어떤 일을 수행하기 위한 단계적 방법
    - 컴퓨터 분야에서 알고리즘을 표현하는 방법은 크게 2가지
        - 의사코드(슈도코드, Pseudocode)와 순서도
2. 좋은 알고리즘이란?
    - 정확성: 얼마나 정확하게 동작하는가
    - 작업량: 얼마나 적은 연산으로 원하는 결과를 얻어내는가(많은 문제에서 성능 분석의 기준으로 알고리즘의 작업량을 비교한다.)
    - 메모리 사용량: 얼마나 적은 메모리를 사용하는가
    - 단순성: 얼마나 단순한가
    - 최적성: 더 이상 개선할 여지없이 최적화되었는가
3. 시간복잡도(Time Complexity)
    - 실제 걸리는 시간 측정
    - 실행되는 명령문 개수를 계산
    - 빅-오(O) 표기법
        - 시간 복잡도 함수 중 가장 큰 영향력을 주는 n에 대한 항만 표시
        - 계수(Coefficient)는 생략하여 표시

# List

## 배열
1. 정의
    - 일정한 자료형의 변수들을 하나의 이름으로 열거하여 사용하는 자료구조
2. 필요성
    - 하나의 선언을 통해서 둘 이상의 변수를 선언할 수 있다.
    - 다수의 변수로는 하기 힘든 작업을 배열을 활용해 쉽게 할 수 있다.

### 1차원 배열
1. 선언
    - 별도의 선언 방법이 없으면 변수에 처음 값을 할당할 때 생성

### 2차원 배열
1. 선언
    - 1차원 list를 묶어놓은 list
    - 2차원 이상의 다차원 list는 차원에 따라 index를 선언
    - 2차원 list의 선언은 행의 길이와 열의 길이를 필요로 한다.
    - Python에서는 데이터 초기화를 통해 변수선언과 초기화가 가능하다.
2. 배열 순회
    - 델타를 이용한 2차 배열 탐색
    ```python
    di = [0, 1, 0, -1]
    dj = [1, 0, -1, 0]
    N = 3
    M = 4
    arr = [[1, 2, 3, 4], [4, 5, 6, 8]]
    # for i in range(N):
    #     for j in range(M):
    #         for k in range(4):
    #             ni = i + di[k]
    #             nj = j + dj[k]
    #             if 0 <= ni < N and 0 <= nj < M:
    #                 print(ni, nj)

    # for i in range(N):
    #     for j in range(M):
    #         for di, dj in [[0, 1], [1, 0], [0, -1], [-1, 0]]:
    #             mi, mj = i + di, j + dj
    #             if 0 <= mi < N and 0 <= mj < M:
    #                 print(mi, mj)

    # 인접 2개의 배열 요소를 탐색하려면
    for i in range(N):
        for j in range(M):
            for k in range(4):
                for d in range(1, 3):
                    li = i + (di[k] * d)
                    lj = j + (dj[k] * d)
                    if 0 <= li < N and 0 <= lj < M:
                        print(li, lj)
    ```
3. 활용
    - 전치 행렬
    ```python
    arr = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]

    for i in range(3):
        for j in range(i):
            arr[i][j], arr[j][i] = arr[j][i], arr[i][j]
    print(arr)
    ```

## 정렬
1. 정의
    - 2개 이상의 자료를 특정 기준에 의해 작은 값부터 큰 값(오름차순: ascending), 혹은 그 반대의 순서대로(내림차순: descending) 재배열하는 것
    - 키: 자료를 정렬하는 기준이 되는 특정 값
    - 대표적인 정렬 방식의 종류
        - 버블 정렬(Bubble Sort)
        - 카운팅 정렬(Counting Sort)
        - 선택 정렬(Selection Sort)
        - 퀵 정렬(Quick Sort)
        - 삽입 정렬(Insertion Sort)
        - 병합 정렬(Merge Sort)

### 버블 정렬
1. 정의
    - 인접한 두 개의 원소를 비교하며 자리를 계속 교환하는 방식
2. 정렬 과정
    - 첫 번째 원소부터 인접한 원소끼리 계속 자리를 교환하면서 맨 마지막 자리까지 이동한다.
    - 한 단계가 끝나면 가장 큰 원소가 마지막 자리로 정렬된다.
    - 시간 복잡도: O(N**2)
    ```python
    def BubbleSort(a, N): # 정렬할 List, N의 원소 개수
    for i in range(N-1, 0, -1): # 범위의 끝 위치
        for j in range(0, i):
            if a[j] > a[j+1]:
                a[j], a[j+1] = a[j+1], a[j]
    ```

### 카운팅 정렬
1. 정의
    - 항목들의 순서를 결정하기 위해 집합에 각 항목이 몇 개씩 있는지 세는 작업을 통해, 선형 시간에 정렬하는 효율적인 알고리즘
2. 제한 사항
    - 정수나 정수로 표현할 수 있는 자료에 대해서만 적용 가능: 각 항목의 발생 횟수를 기록하기 위해, 정수 항목으로 인덱스 되는 카운트들의 배열을 사용하기 때문이다.
    - 카운트들을 위한 충분한 공간을 할당하려면 집합 내의 가장 큰 정수를 알아야 한다.
    - 시간 복잡도: O(n+k) -> n은 리스트 길이, k는 정수의 최댓값
3. 정렬 과정
    - 1단계: Data에서 각 항목들의 발생 횟수를 세고, 정수 항목들로 직접 인덱스되는 카운트 배열 counts에 저장한다.
    - 2단계: 정렬된 집합에서 각 항목의 앞에 위치할 항목의 개수를 반영하기 위해 counts의 원소를 조정한다.
    ```python

    # A [] -- 입력 배열 (1 to k)
    # B [] -- 정렬된 배열 (1 to k)
    # C [] -- 카운트 배열 (1 to k+1)

    def Counting_Sort(A, B, k):
    C = [0] * (k+1)
    
    for i in range(len(A)):
        C[A[i]] += 1
    
    for i in range(1, len(C)):
        C[i] += C[i-1]

    for i in range(len(B)-1, -1, -1):
        C[A[i]] -= 1
        B[C[A[i]]] = A[i]
    ```

### 선택 정렬
1. 정의
    - 주어진 자료 중 가장 작은 값의 원소부터 차례대로 선택하여 위치를 교환하는 방식
2. 정렬 과정
    - 주어진 리스트 중 최솟값을 찾는다.
    - 그 값을 리스트의 맨 앞에 위치한 값과 교환한다.
    - 맨 처음 위치를 제외한 나머지 리스트를 대상으로 위의 과정을 반복한다.
    - 미정렬 원소가 하나 남은 상황에서는 마지막 원소가 가장 큰 값을 갖게 되므로, 실행을 종료하고 선택 정렬이 완료된다.
    - 시간 복잡도: O(n**2)
3. 구현
```python
def SelectionSort(a, N):
    for i in range(N-1):
        minIdx = i
        for j in range(i+1, N):
            if a[minIdx] > a[j]:
                minIdx = j
        a[i], a[minIdx] = a[minIdx], a[i]
```

### 정렬 알고리즘 비교
- 버블 정렬: `O(n**2) ~ O(n**2)` 비교와 교환 -> 코딩이 가장 손쉽다
- 카운팅 정렬: `O(n+k) ~ O(n+k)` 비교환 방식 -> n이 비교적 작을 때만 가능하다.
- 선택 정렬: `O(n**2) ~ O(n**2)` 비교와 교환 -> 교환의 횟수가 버블, 삽입정렬보다 적다.
- 퀵 정렬: `O(n log n) ~ O(n**2)` 분할 정복 -> 최악의 경우 O(n**2)이지만, 평균적으로는 가장 빠르다.
- 삽입 정렬: `O(n**2) ~ O(n**2)` 비교와 교환 -> n의 개수가 작을 때 효과적이다.
- 병합 정렬: `O(n log n) ~ O(n log n)` 분할 정복 -> 연결리스트의 경우 가장 효율적인 방식

### 완전탐색(Brute-Force)
1. 정의
    - 문제의 해법으로 생각할 수 있는 모든 경우의 수를 나열해보고 확인하는 기법
    - 모든 경우의 수를 테스트한 후, 최종 해법을 도출한다.
    - 일반적으로 경우의 수가 상대적으로 적을 때 유용하다.
    - 수행 속도는 느리지만, 해답을 찾아내지 못할 확률이 낮다.
    - 주어진 문제를 풀 때, 우선 완전 탐색으로 접근하여 해답을 도출한 후, 성능 개선을 위해 다른 알고리즘을 사용하고 해답을 확인하는 것이 바람직하다.

### 탐욕 알고리즘(Greedy Algorithm)
1. 정의
    - 최적해를 구하는 근시안적 방법
    - 여러 경우 중 하나를 결정해야 할 때마다 그 순간에 최적이라고 생각되는 것을 선택해 나가는 방식으로 진행하여 최종적인 해답에 도달한다.
    - 각 선택 시점에서 이루어지는 결정은 지역적으로는 최적이지만, 그 선택들을 계속 수집하여 최종적인 해답을 만들었다고 해서 그것이 최적이라는 보장은 없다.
    - 일반적으로, 생각을 바로 구현하면 Greedy 접근이 된다.
2. 동작 과정
    - 해 선택: 현재 상태에서 부분 문제의 최적해를 구한 뒤, 이를 부분해 집합(Solution Set)에 추가한다.
    - 실행 가능성 검사: 새로운 부분해 집합이 실행 가능한지를 확인한다. 곧, 문제의 제약 조건을 위반하지 않는지를 검사한다.
    - 해 검사: 새로운 부분해 집합이 문제의 해가 되는지를 확인한다. 아직 전체 문제의 해가 완성되지 않았다면 처음부터 다시 시작

### 부분집합 생성
1. 비트 연산자
    - `&`: 비트 단위로 and 연산
    - `|`: 비트 단위로 or 연산
    - `<<`: 피연산자의 비트 열을 왼쪽으로 이동
        - 1 << n: 원소가 n 개인 경우의 모든 부분집합의 수를 의미한다(2**n)
    - `>>`: 피연산자의 비트 열을 오른쪽으로 이동
2. 주어진 부분집합을 생성하는 방법
```python
bit = [0, 0, 0, 0]
for i in range(2):
    bit[0] = i
    for j in range(2):
        bit[1] = j
        for k in range(2):
            bit[2] = k
            for l in range(2):
                bit[3] = l
                print_subset(bit) # [0, 0, 0, 0], [0, 0, 0, 1], ..., [1, 1, 1, 1]
```
 
## Search
1. 정의
    - 저장된 자료 중 원하는 항목을 찾는 작업
    - 목적하는 탐색 키를 가진 항목을 찾는 것
        - 탐색 키(Search Key): 자료를 구별하여 인식할 수 있는 키
    - 검색의 종류
        - 순차 검색(sequential search)
        - 이진 검색(binary search)
        - 해쉬(hash)

### 순차 탐색
1. 정의
    - 일렬로 되어 있는 자료를 순서대로 검색하는 방법(가장 간단하고 직관적)
    - 배열이나 연결 리스트 등 순차구조로 구현된 자료구조에서 원하는 항목을 찾을 때 유용
    - 알고리즘이 단순하여 구현이 쉽지만, 검색 대상의 수가 많은 경우 수행시간이 급격히 증가하여 비효율적이다.
    - 정렬되어 있지 않은 경우와 정렬되어 있는 경우로 나누어 생각할 수 있다.
2. 검색 과정
    - 첫 번째 원소부터 순서대로 검색 대상과 키 값이 같은 원소가 있는지 비교하며 찾는다.
    - 키 값이 동일한 원소를 찾으면 그 원소의 인덱스를 반환한다.
    - 자료구조의 마지막에 이를 때까지 검색 대상을 찾지 못하면 검색 실패
3. 정렬되어 있지 않은 경우
    - 찾고자 하는 원소의 순서에 따라 비교횟수가 결정된다.
        - 첫 번째 원소를 찾을 때는 1번, 두 번째 원소를 찾을 때는 2번 비교
        - 정렬되지 않은 자료에서의 순차 검색의 평균 비교 횟수
            - (1/n) * (1+2+3+4+...+n) = (n+1)/2: 시간복잡도 O(n)
    ```python
    def sequentialSearch(a, n, key): # a = 검색할 리스트, n은 원소의 개수, key는 찾는 값
        i = 0
        while i < n and a[i] != key:
            i += 1
        if i < n:
            return i
        else:
            return -1
    ```
4. 정렬되어 있는 경우
    - 자료가 오름차순으로 정렬된 상태에서 검색을 실시한다고 가정할 때, 자료를 순차적으로 검색하면서 키 값을 비교하여, 원소의 키 값이 검색 대상의 키 값보다 크면 찾는 원소가 없다는 것이므로 더 이상 검색하지 않고 검색을 종료한다.
    - 정렬이 되어 있으므로, 검색 실패를 반환하는 경우 평균 비교 횟수가 반으로 줄어든다.
    - 시간 복잡도: O(n)
    ```python
    def sequential_Search(a, n, key):
        while i < n and a[i] < key:
            i += 1
        if i < n and a[i] == key:
            return i
        else:
            return -1
    ```

### 이진 탐색(Binary search)
1. 정의
    - 자료의 가운데에 있는 항목의 키 값과 비교하여 다음 검색의 위치를 결정하고 검색을 계속 진행하는 방법, 목적 키를 찾을 때까지 이진 검색을 순환적으로 반복 수행함으로써 검색 범위를 반으로 줄여가면서 보다 빠르게 검색을 수행함
2. 검색 과정
    - 자료의 중앙에 있는 원소를 고른다.
    - 중앙 원소의 값과 찾고자 하는 목표 값을 비교한다.
    - 목표 값이 중앙 원소의 값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색을 수행하고, 크다면 자료의 오른쪽 반에 대해서 새로 검색을 수행한다.
    - 찾고자 하는 값을 찾을 때까지 앞의 세 과정을 반복한다.
3. 구현
    - 검색 범위의 시작점과 종료점을 이용하여 검색을 반복 수행
    - 이진 검색의 경우, 자료에 삽입이나 삭제가 발생했을 때 배열의 상태를 항상 정렬상태로 유지하는 추가 작업이 필요하다.
    ```python
    def binarySearch(a, N, key):
    start = 0
    end = N - 1
    while start <= end:
        middle = (start + end) // 2
        if a[middle] == key: # 검색 성공
            return True
        elif a[middle] > key:
            end = middle - 1
        else:
            start = middle + 1
    return False # 검색 실패

    def binarySearch2(a, low, high, key): # 재귀함수 활용 버전
        if low > high: # 검색 실패
            return False
        else:
            middle = (low + high) // 2
            if key == a[middle]: # 검색 성공
                return True
            elif key < a[middle]:
                return binarySearch2(a, low, middle-1, key)
            elif key > a[middle]:
                return binarySearch2(a, middle+1, high, key)
    ```

### 인덱스
1. 정의
    - Database에서 유래했으며, 테이블에 대한 동작 속도를 높여주는 자료 구조를 일컫는다.
    Database분야가 아닌 곳에서는 Look up table 등의 용어를 사용하기도 한다.
    - 인덱스를 저장하는데 필요한 디스크 공간은 보통 테이블을 저장하는데 필요한 디스크 공간보다 작다. 보통 인덱스는 키-필드만 갖고 있고, 테이블의 다른 세부 항목들은 갖고 있지 않기 때문이다.
2. 배열을 사용한 인덱스
    - 대량의 데이터를 매번 정렬하면, 프로그램의 반응은 느려질 수밖에 없다. 이러한 대량 데이터의 성능 저하 문제를 해결하기 위해 배열 인덱스를 사용할 수 있다.
    - 원본 데이터에 데이터가 삽입될 경우, 상대적으로 크기가 작은 인덱스 배열을 정렬하기 때문에 속도가 빠르다.

### Selection Algorithm
1. 정의
    - 저장되어 있는 자료로부터 k번째로 큰 혹은 작은 원소를 찾는 방법
    - 최솟값, 최댓값, 혹은 중간값을 찾는 알고리즘을 의미하기도 한다.
2. 선택 과정
    - 정렬 알고리즘을 이용하여 자료 정렬하기
    - 원하는 순서에 있는 원소 가져오기
3. k번째로 작은 원소를 찾는 알고리즘
    - 1번부터 k번째까지 작은 원소들을 찾아 배열의 앞쪽으로 이동시키고, 배열의 k번째를 반환한다.
    - k가 비교적 작을 때 유용하며 O(kn)의 수행시간을 필요로 한다.
    ```python
    def select(arr, k):
    for i in range(k):
        minIdx = i
        for j in range(i+1, len(arr)):
            if arr[minIdx] > arr[j]:
                minIdx = j
        arr[i], arr[minIdx] = arr[minIdx], arr[i]
    return arr[k-1]
    ```

# String

## 문자열
1. 문자의 표현
    - 메모리는 숫자만을 저장할 수 있기 때문에 A라는 글자의 모양 그대로 비트맵으로 저장하는 방법을 사용하지 않는 한(이 방법은 메모리 낭비가 심하다) 각 문자에 대해서 대응되는 숫자를 정해 놓고 이것을 메모리에 저장하는 방법이 사용된다.
    - 대소문자 합쳐 52자이므로, 6(64)비트면 모두 표현할 수 있다.
    - ASCII는 7bit 인코딩으로 128문자를 표현하며 33개의 출력 불가능한 제어 문자들과 공백을 비롯한 95개의 출력 가능한 문자들로 이루어져 있다.
        - 0: 48~57
        - a: 97~122
        - A: 65~90
    - 확장 아스키는 표준 문자 이외의 악센트 문자, 도형 문자, 특수 문자, 특수 기호 등 부가적인 문자를 128개 추가할 수 있게 하는 부호이다.
        - 표준 아스키는 7bit를 사용하여 문자를 표현하는 데 비해 확장 아스키는 1B 내의 8 bit를 모두 사용함으로써 추가적인 문자를 표현할 수 있다.
        - 컴퓨터 생산자와 소프트웨어 개발자가 여러 가지 다양한 문자에 할당할 수 있도록 하고 있다. 이렇게 할당된 확장 부호는 표준 아스키와 같이 서로 다른 프로그램이나 컴퓨터 사이에 교환되지 못한다.
        - 따라서 표준 아스키는 마이크로 컴퓨터 하드웨어 및 소프트웨어 사이에서 세계적으로 통용되는 데 비해, 확장 아스키는 프로그램이나 컴퓨터 또는 프린터가 그것을 해독할 수 있도록 설계되어 있어야만 올바로 해독될 수 있다.
2. Python 문자열 처리
    - char 타입 없음
    - 텍스트 데이터의 취급방법이 통일되어 있다.
    - 문자열 기호
        - `'`, `"`, `'''`, `"""`
        - 연결: 문자열 `+` 문자열
        - 반복: 문자열 `*` 수
    - 문자열은 시퀀스 자료형으로 분류되고, 시퀀스 자료형에서 사용할 수 있는 인덱싱, 슬라이싱 연산들을 사용할 수 있다.
        - 제공되는 메소드: replace(), split(), isalpha(), find() 등
        - 요소값을 변경할 수는 없음(immutable)
    - 언어별 차이점
        - c는 아스키 코드로 저장
        - java는 유니코드(UTF16, 2byte)로 저장
        - 파이썬은 유니코드(UTF8)로 저장

## 패턴 매칭
1. 알고리즘
    - 고지식한 패턴 검색 알고리즘(Brute Force)
        - 본문 문자열을 처음부터 끝까지 차례대로 순회하면서 패턴 내의 문자들을 일일이 비교하는 방식으로 동작
        - 시간 복잡도: O(MN)
        ```python
        def BruteForce_for(pattern, text):
            for i in range(len(text) - len(pattern) + 1):
                # pattern의 처음부터 텍스트 문자열과 비교
                for j in range(len(pattern)):
                    if text[i+j] != pattern[j]:
                        break
                else:
                    return i
            else:
                return -1
        ```
    - 카프-라빈 알고리즘
    - KMP 알고리즘
        - 불일치가 발생한 텍스트 스트링의 앞 부분에 어떤 문자가 있는지를 미리 알고 있으므로, 불일치가 발생한 앞 부분에 대하여 다시 비교하지 않고 매칭을 수행
        - 패턴을 전처리하여 배열 next[M]을 구해서 잘못된 시작을 최소화한다.
        - 시간 복잡도: O(M+N)
    - 보이어-무어 알고리즘
        - 오른쪽으로 왼쪽으로 비교
        - 대부분의 상용 소프트웨어에서 채택하고 있는 알고리즘
        - 보이어-무어 알고리즘은 패턴의 오른쪽 끝에 있는 문자가 불일치하고 이 문자가 패턴 내에 존재하지 않는 경우, 이동 거리는 무려 패턴의 길이 만큼이 된다.
        - 시간 복잡도: O(N)

# 스택

## 특성
- 물건을 쌓아 올리듯 자료를 쌓아 올린 형태의 자료구조
- 스택에 저장된 자료는 선형 구조를 갖는다.
    - 선형 구조: 자료 간의 관계가 1:1
    - 비선형 구조: 자료 간의 관계가 1:N의 관계
- 스택에 자료를 삽입하거나 꺼낼 수 있다.
- 후입선출(LIFO): Last-in-First-out

## 구현
1. 필요 자료구조 및 연산
    - 자료구조: 자료를 선형으로 저장할 저장소
        - 스택에서 마지막으로 삽입된 원소의 위치를 top이라고 부른다.
    - 연산
        - 삽입(push)
        - 삭제(pop)
        - 스택이 공백인지 확인: isEmpty()
        - 스택의 top에 있는 item(원소)을 반환하는 연산: peek()
2. 삽입/삭제 과정
    ```python
    def push(item, size):
        global top
        top += 1
        if top == size:
            print('overflow') # 디버깅용, 없어도 상관없음
        else:
            stack[top] = item

    def pop():
        global top
        if top == -1:
            print('underflow') # 디버깅용
            return 0
        else:
            top -= 1
            return stack[top+1]

    size = 10
    stack = [0] * size
    top = -1

    push(10, size)
    top += 1 # push(20)
    stack[top] = 20

    if top > -1:
        top -= 1
        print(stack[top+1])
    ```
3. 고려사항
    - 1차원 배열을 사용하여 구현할 경우 구현이 용이하다는 장점이 있지만 스택의 크기를 변경하기 어렵다는 단점
    - 이를 해결하기 위한 방법으로 저장소를 동적으로 할당하여 스택을 구현하는 방법이 있다. 동적 연결리스트를 이용하여 구현하는 방법을 의미하는데, 구현이 복잡하다는 단점이 있지만 메모리를 효율적으로 사용한다는 장점을 가진다.

## Memoization
- 피보나치 수열을 구하는 함수를 재귀함수로 구현하면 '엄청난 중복 호출이 존재'하게 된다. 시간복잡도: O(2**n)
    - 피보나치 수열의 Call Tree(함수의 호출단계를 나타내는 것)
- 메모이제이션은 컴퓨터 프로그램을 실행할 때 이전에 계산한 값을 메모리에 저장해서 매번 다시 계산하지 않도록 하여 전체적인 실행속도를 빠르게 하는 기술이다. 동적 계획법의 핵심이 되는 기술(동적 계획법의 중간단계)
- 피보나치 수열을 구하는 알고리즘에서 fibo(n)의 값을 계산하자마자 저장하면, 실행시간을 O(n)으로 줄일 수 있다.
```python
def fibo1(n):
    global memo
    if n >= 2 and len(memo) <= n:
        memo.append(fibo1(n-1)+fibo1(n-2))
    return memo[n]

memo = [0, 1]
```

## DP(Dynamic Programming): 동적 계획
- 그리디 알고리즘과 같이 최적화 문제를 해결하는 알고리즘
- 먼저 입력 크기가 작은 부분 문제들을 모두 해결한 후에 그 해들을 이용하여 보다 큰 크기의 부분 문제들을 해결하여, 최종적으로 원래 주어진 입력의 문제를 해결하는 알고리즘이다.

- 구현 방식
    1. 문제를 부분 문제로 분할한다.
    2. 부분문제로 나눈 이후, 가장 작은 부분 문제부터 해를 구한다.
    3. 그 결과는 테이블에 저장하고, 테이블에 저장된 부분 문제의 해를 이용하여 상위 문제의 해를 구한다.
        - recursive(재귀적) 방식
        - iterative 방식
        - memoization을 재귀적 구조에 사용하는 것보다 반복적 구조로 DP를 구현한 것이 성능 면에서 보다 효율적이다.
        - 재귀적 구조는 내부에 시스템 호출 스택을 사용하는 오버헤드가 발생하기 때문이다(함수의 호출복귀시간이 길다는 뜻).

## DFS(깊이 우선탐색, Depth First Search)
1. 정의
    - 비선형구조인 그래프 구조는 그래프로 표현된 모든 자료를 빠짐없이 검색하는 것이 중요하다.
    - 시작 정점의 한 방향으로 갈 수 있는 경로가 있는 곳까지 깊이 탐색해 가다가 더 이상 갈 곳이 없게 되면, 가장 마지막에 만났던 갈림길 간선이 있는 정점으로 되돌아와서 다른 방향의 정점으로 탐색을 계속 반복하여 결국 모든 정점을 방문하는 순회방법
    - 가장 마지막에 만났던 갈림길의 정점으로 되돌아가서 다시 깊이 우선 탐색을 반복해야 하므로 후입선출 구조의 스택을 사용해야 한다.
2. 구현
```python
'''
visited[], stack[] 초기화
DFS(v)
    시작점 v 방문
    visited[v] <- True
    while
        if (v의 인접 정점 중 방문 안 한 정점 w가 있으면)
            push(v)
            v <- w (w 방문)
            visited[w] <- True
        else
            if (스택이 비어 있지 않으면)
                v <- pop(stack)
            else
                break
'''

adjList = [[1, 2],      # 0
           [0, 3, 4],   # 1
           [0, 4],      # 2
           [1, 5],      # 3
           [1, 2, 5],   # 4
           [3, 4, 6],   # 5
           [5]]         # 6

def dfs(v, N):
    visited = [0] * N   # visited 초기화
    stack = [0] * N   # 공백 스택 생성
    top = -1

    visited[v] = 1      # 시작점 방문 표시
    while True:
        for w in adjList[v]: # v의 인접 정점 중 방문 안 한 정점 w가 있으면
            if visited[w] == 0:
                top += 1     # push(v)
                stack[top] = v
                v = w        # w 방문
                print(v)     # 방문 확인
                visited[w] = 1
                break
        else:                # w가 없으면
            if top != -1:
                v = stack[top]
                top -= 1
            else:
                break

dfs(1, 7)
```